{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf4f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pymystem3\n",
    "import nltk\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3afb6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train/news_eval_train.xml'\n",
    "test_path = 'data/test/news_eval_test.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0293c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RGX = re.compile(u'[A-Za-zА-Яа-я0-9]+', re.UNICODE)\n",
    "\n",
    "def split(string):\n",
    "    words = re.findall(SPLIT_RGX, string)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db55cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = pymystem3.Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8eb6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(path):\n",
    "    d = {'+': 1, '0': 0, '-': -1}\n",
    "    \n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    data, target = [], []\n",
    "    for sent in tqdm(root):\n",
    "        t = sent.find('evaluation').text.strip()\n",
    "        if t not in d:\n",
    "            continue\n",
    "        target.append(d[t])\n",
    "        \n",
    "        t = sent.find('speech').text.strip()\n",
    "        t = split(' '.join(stem.lemmatize(' '.join(list(map(lambda x: x.lower(), split(t)))))).strip())\n",
    "        data.append(t)\n",
    "        \n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eafa319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4260/4260 [00:03<00:00, 1156.18it/s]\n",
      "100%|█████████████████████████████████████| 5500/5500 [00:04<00:00, 1283.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_text, train_target = parse_xml(train_path)\n",
    "test_text, test_target = parse_xml(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf1708a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/svasilyev/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b41eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(data, remove_words):\n",
    "    remove_words = set(remove_words)\n",
    "    res = []\n",
    "    for d in data:\n",
    "        res.append([e for e in d if e not in remove_words])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281226a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_nostop = remove_words(train_text, stopwords)\n",
    "test_text_nostop = remove_words(test_text, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93502502",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = list(map(lambda x: ' '.join(x), train_text))\n",
    "test_text = list(map(lambda x: ' '.join(x), test_text))\n",
    "train_text_nostop = list(map(lambda x: ' '.join(x), train_text_nostop))\n",
    "test_text_nostop = list(map(lambda x: ' '.join(x), test_text_nostop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1898ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(train_text)\n",
    "vect_nostop = CountVectorizer().fit(train_text_nostop)\n",
    "train_fea = vect.transform(train_text).toarray()\n",
    "test_fea = vect.transform(test_text).toarray()\n",
    "train_fea_nostop = vect_nostop.transform(train_text_nostop).toarray()\n",
    "test_fea_nostop = vect_nostop.transform(test_text_nostop).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4886ee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.6153509731029958\n",
      "F1-micro:\t0.6153509731029958\n",
      "F1-macro:\t0.5623278684302425\n"
     ]
    }
   ],
   "source": [
    "# 01\n",
    "# logreg\n",
    "# binary vectors\n",
    "# with stopwords\n",
    "\n",
    "clf_01 = LogisticRegression(C=0.05, max_iter=500, random_state=0).fit((train_fea > 0).astype(int), train_target)\n",
    "preds_01 = clf_01.predict((test_fea > 0).astype(int))\n",
    "print(f'Accuracy:\\t{accuracy_score(test_target, preds_01)}')\n",
    "print(f'F1-micro:\\t{f1_score(test_target, preds_01, average=\"micro\")}')\n",
    "print(f'F1-macro:\\t{f1_score(test_target, preds_01, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90aa2c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.6146949486114148\n",
      "F1-micro:\t0.6146949486114148\n",
      "F1-macro:\t0.5671031718658105\n"
     ]
    }
   ],
   "source": [
    "# 02\n",
    "# logreg\n",
    "# tfs vectors\n",
    "# with stopwords\n",
    "\n",
    "clf_02 = LogisticRegression(C=0.05, max_iter=500, random_state=0).fit(train_fea, train_target)\n",
    "preds_02 = clf_02.predict(test_fea)\n",
    "print(f'Accuracy:\\t{accuracy_score(test_target, preds_02)}')\n",
    "print(f'F1-micro:\\t{f1_score(test_target, preds_02, average=\"micro\")}')\n",
    "print(f'F1-macro:\\t{f1_score(test_target, preds_02, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8050f457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.6094467526787667\n",
      "F1-micro:\t0.6094467526787667\n",
      "F1-macro:\t0.5813070490171646\n"
     ]
    }
   ],
   "source": [
    "# 03\n",
    "# logreg\n",
    "# tfs-idf vectors\n",
    "# with stopwords\n",
    "\n",
    "idf = np.log(train_fea.shape[0] / (train_fea > 0).astype(int).sum(axis=0))\n",
    "\n",
    "clf_03 = LogisticRegression(C=0.1, max_iter=1000, random_state=0).fit(train_fea * idf, train_target)\n",
    "preds_03 = clf_03.predict(test_fea * idf)\n",
    "print(f'Accuracy:\\t{accuracy_score(test_target, preds_03)}')\n",
    "print(f'F1-micro:\\t{f1_score(test_target, preds_03, average=\"micro\")}')\n",
    "print(f'F1-macro:\\t{f1_score(test_target, preds_03, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32013f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.6125082003061447\n",
      "F1-micro:\t0.6125082003061447\n",
      "F1-macro:\t0.5692549088194366\n"
     ]
    }
   ],
   "source": [
    "# 04\n",
    "# logreg\n",
    "# binary vectors\n",
    "# withOUT stopwords\n",
    "\n",
    "clf_04 = LogisticRegression(C=0.09, max_iter=500, random_state=0).fit((train_fea_nostop > 0).astype(int), train_target)\n",
    "preds_04 = clf_04.predict((test_fea_nostop > 0).astype(int))\n",
    "print(f'Accuracy:\\t{accuracy_score(test_target, preds_04)}')\n",
    "print(f'F1-micro:\\t{f1_score(test_target, preds_04, average=\"micro\")}')\n",
    "print(f'F1-macro:\\t{f1_score(test_target, preds_04, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44a7aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.6050732560682266\n",
      "F1-micro:\t0.6050732560682266\n",
      "F1-macro:\t0.5675443959376305\n"
     ]
    }
   ],
   "source": [
    "# 05\n",
    "# logreg\n",
    "# tfs vectors\n",
    "# withOUT stopwords\n",
    "\n",
    "clf_05 = LogisticRegression(C=0.15, max_iter=500, random_state=0).fit(train_fea_nostop, train_target)\n",
    "preds_05 = clf_05.predict(test_fea_nostop)\n",
    "print(f'Accuracy:\\t{accuracy_score(test_target, preds_05)}')\n",
    "print(f'F1-micro:\\t{f1_score(test_target, preds_05, average=\"micro\")}')\n",
    "print(f'F1-macro:\\t{f1_score(test_target, preds_05, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "910cb438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t0.6096654275092936\n",
      "F1-micro:\t0.6096654275092936\n",
      "F1-macro:\t0.5647910278163352\n"
     ]
    }
   ],
   "source": [
    "# 06\n",
    "# logreg\n",
    "# tfs-idf vectors\n",
    "# withOUT stopwords\n",
    "\n",
    "idf = np.log(train_fea_nostop.shape[0] / (train_fea_nostop > 0).astype(int).sum(axis=0))\n",
    "\n",
    "clf_06 = LogisticRegression(C=0.005, max_iter=1000, random_state=0).fit(train_fea_nostop * idf, train_target)\n",
    "preds_06 = clf_06.predict(test_fea_nostop * idf)\n",
    "print(f'Accuracy:\\t{accuracy_score(test_target, preds_06)}')\n",
    "print(f'F1-micro:\\t{f1_score(test_target, preds_06, average=\"micro\")}')\n",
    "print(f'F1-macro:\\t{f1_score(test_target, preds_06, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7917566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (-): 0.7031214399635451\n",
      "F1 (0): 0.3732317736670294\n",
      "F1 (+): 0.6180198698184309\n"
     ]
    }
   ],
   "source": [
    "print(f'F1 (-): {f1_score((np.array(test_target) == -1).astype(int), (preds_06 == -1).astype(int))}')\n",
    "print(f'F1 (0): {f1_score((np.array(test_target) == 0).astype(int), (preds_06 == 0).astype(int))}')\n",
    "print(f'F1 (+): {f1_score((np.array(test_target) == 1).astype(int), (preds_06 == 1).astype(int))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c46c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
